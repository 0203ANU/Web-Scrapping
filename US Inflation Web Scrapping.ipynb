{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c63273",
   "metadata": {},
   "source": [
    "## Web Scrapping using BeautifulSoup - US Inflation Rate \n",
    "\n",
    "Data Source: [Bureau of Labor Stastitics](https://data.bls.gov/pdq/SurveyOutputServlet) <br><br>\n",
    "\n",
    "We are scrapping tabular data for US Inflation Rate from the website [Bureau of Labor Stastitics](https://data.bls.gov/pdq/SurveyOutputServlet). We will dicuss implementation of webscrapping using python framework called BeautifulSoup. It is a thrid party library for pulling data HTML and XML files.\n",
    "<br>\n",
    "Steps involved in webscrapping:\n",
    "\n",
    "1. Send an HTTP request to the URL of the webpage. The sever of the website responds to the request by returning HTML contents of the webpage. For this we will use third party library for python-requests. \n",
    "\n",
    "2. Now that we have the HTML contents, we need to parse the data. We can not parse the data simply through string processing. BeautifulSoup library is that it is built on the top of the HTML parsing libraries like html5lib, lxml, html.parser, etc (multiple parsing methods available to parse the data).  \n",
    "\n",
    "3. We need to navigate and search the parsed tree using Beautiful Soup. \n",
    "<br><br>\n",
    "\n",
    "**Step 1: Install required third-party libraries**\n",
    "``` python\n",
    "pip install requests          # for connecting to server\n",
    "pip install  html5lib         # parser method\n",
    "pip install bs4               # Librabry for Beautiful Soup\n",
    "\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1037d5",
   "metadata": {},
   "source": [
    "**Step 2: Accessing HTML content from the webpage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90fca93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pacakages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import html5lib\n",
    "\n",
    "#load the website link in requests.get() and chain .text to get the html content printed nicely\n",
    "html_text = requests.get(\"https://data.bls.gov/pdq/SurveyOutputServlet\").text\n",
    "\n",
    "#print(html_text)                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb6fde",
   "metadata": {},
   "source": [
    "There are various parser methods available but we have taken 'html5lib' in our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65af51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_text, 'html5lib')         #html5lib is the parser method passed in string format\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0f7120",
   "metadata": {},
   "source": [
    "To access the elements from html content, we will inspect the website. <br>\n",
    "1. Right click on table header and select inspect > html content will be displayed on right side of the screen <br>\n",
    "The content we want is stored in 'table' tag having class as 'regular-data'. <br> We will use .find() function to find the tag 'table' having class 'regular-data' using BeautifulSoup instance created in above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af8a2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')\n",
    "for table in tables:\n",
    "    print(\"Different classes in tag table are:\",table.get('class'))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa831f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"verdana md\" id=\"bodytext\">\n",
      "\t\t\n",
      "\n",
      "\t<!-- 1COL LAYOUT COL1 END -->\n",
      "\n",
      "\t<!--no_index_end-->\n",
      "\t<!-- MAIN CONTENT BEGIN -->\n",
      "\t<h1 class=\"warning\">\n",
      "\t\t<img align=\"left\" border=\"0\" height=\"35\" src=\"/images/icon_warn.gif\" width=\"35\"/> Â  Notice\n",
      "\t</h1>\n",
      "\n",
      "\t<p>Wednesday, April 19, 2023 4:17:42 PM EDT</p>\n",
      "\n",
      "\t\n",
      "\t<p>The database is currently unavailable.</p>\n",
      "\t\n",
      "\t<div class=\"dbdown_message\">Your request was invalid for this Data Access Service. Please attempt other data requests. Thank you for using LABSTAT.</div>\n",
      "\t\n",
      "\t<!-- MAIN CONTENT END -->\n",
      "\n",
      "\t<!--no_index_start-->\n",
      "\t<!-- 2COL LAYOUT COL2 BEGIN -->\n",
      "\t\t\t<!--#include virtual=\"/include/global/social_media.stm\"-->\n",
      "\t\t</div>\n"
     ]
    }
   ],
   "source": [
    "class_div = soup.find('div',class_ = 'verdana md')\n",
    "print(class_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39bffba",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Look at the html content above. The response we got: <br><br>\"*The database is currently unavailable.Your request was invalid for this Data Access Service. Please attempt other data requests.*\" <br>\n",
    "\n",
    "This means at this point of time, the site has restricted access of the data. Upon searching the web, there's another website which provides same information.<br><br>\n",
    "Now the source changes to: [US Inflation Calculator](https://www.usinflationcalculator.com/inflation/historical-inflation-rates/)\n",
    "<br> Rewriting **step two**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be60c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pacakages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import html5lib\n",
    "\n",
    "#load the website link in requests.get() and chain .text to get the html content printed nicely\n",
    "html_text = requests.get(\"https://www.usinflationcalculator.com/inflation/historical-inflation-rates/\").text\n",
    "\n",
    "#print(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4277af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_text,'html5lib')\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a977c676",
   "metadata": {},
   "source": [
    "The data we want is present in tag 'table' with no specific class. Let's see if the html content have multiple tags as 'table'. If not, we can directly specify tag 'table' in BeautifulSoup instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f10a0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-73e97fd4a639>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'table'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Different classes in tag table are:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "tables = soup.find_all('table')\n",
    "for table in tables:\n",
    "    print(\"Different classes in tag table are:\",table.get('class'))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ee905",
   "metadata": {},
   "source": [
    "Seems likes there's only one table with no specific class. Let's pass it to BeautifulSoup object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0609f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table')\n",
    "#print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b34a9",
   "metadata": {},
   "source": [
    "All the rows for the table are stored inside tag 'tr'. Here, we need to loop through each row. So far, we are in tag 'table' > tag 'tr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67937626",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_all('tr')\n",
    "#print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee65026",
   "metadata": {},
   "source": [
    "Inside the tag 'tr', values for year column are stored in tag 'th' and values for other column values are stored in tag 'td' <br><br>\n",
    "Approach:\n",
    "1. Create two different lists to store year values and other column values\n",
    "2. Create two dataframe \n",
    "3. Concat year and other column dataframe into final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87067f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigating to column values for year column\n",
    "for row in rows:\n",
    "    year_values = row.find_all('th')      #year values are present in tag 'th'\n",
    "    #print(year_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2a48e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigating to column values\n",
    "for row in rows:\n",
    "    column_values = row.find_all('td')      #all the column values are present in tag 'td'\n",
    "   #print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884b48ea",
   "metadata": {},
   "source": [
    "Notice, empty list at the very beginning of the output. Let's skip it using IF statement and scrap the column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12a98dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pacakages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import html5lib\n",
    "\n",
    "#load the website link in requests.get() and chain .text to get the html content printed nicely\n",
    "html_text = requests.get(\"https://www.usinflationcalculator.com/inflation/historical-inflation-rates/\").text\n",
    "\n",
    "soup = BeautifulSoup(html_text,'html5lib')         #BeautifulSoup object with html5lib parser\n",
    "table = soup.find('table')                         #tabluar data in html content\n",
    "\n",
    "year_column = []                                   #catching the year values\n",
    "values_list = []                                   #catching the column values\n",
    "\n",
    "rows = table.find_all('tr')                        #all the rows in table\n",
    "for row in rows:\n",
    "    column_values = row.find_all('td')             #data for each column except year column\n",
    "    if column_values != []: \n",
    "        values = {}                                #dictionary for values\n",
    "        \n",
    "        values['Jan'] = column_values[0].text\n",
    "        values['Feb'] = column_values[1].text\n",
    "        values['Mar'] = column_values[2].text\n",
    "        values['Apr'] = column_values[3].text\n",
    "        values['May'] = column_values[4].text\n",
    "        values['Jun'] = column_values[5].text\n",
    "        values['Jul'] = column_values[6].text\n",
    "        values['Aug'] = column_values[7].text\n",
    "        values['Sep'] = column_values[8].text\n",
    "        values['Oct'] = column_values[9].text\n",
    "        values['Nov'] = column_values[10].text\n",
    "        values['Dec'] = column_values[11].text\n",
    "        values['Average'] = column_values[12].text\n",
    "        #print(values)\n",
    "    values_list.append(values)\n",
    "    \n",
    "    year = {}                                         #dictionary for year values\n",
    "    year_values = row.find_all('th')                  #data for year column\n",
    "    year['Year'] = year_values[0].text\n",
    "    #print(year)\n",
    "    year_column.append(year)                          #add the dict year to year_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50febe",
   "metadata": {},
   "source": [
    "Let's create two different dataframes from year column and other columns and later combine both of them into one final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6b397f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                    #import pandas\n",
    "values = pd.DataFrame(values_list)                     #other columns to dataframe\n",
    "years = pd.DataFrame(year_column)                      #year column to dataframe\n",
    "years = years[1:]                                      # little bit cleaning for year column\n",
    "\n",
    "df = pd.concat([years,values], axis = 1)               #concat the two dataframes\n",
    "df = df[:-1]\n",
    "\n",
    "import numpy as np\n",
    "df['Apr'].iloc[-1] = np.NaN\n",
    "\n",
    "#saving file to csv\n",
    "df.to_csv(\"US Inflation 1914-2023.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5385d7c8",
   "metadata": {},
   "source": [
    "**Now that we have succesfully scrape data from the website, we can explore the data and answer research questions :) <br><br>\n",
    "Let's see what all information we can derive from this particular data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0aeabb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1914</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1916</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>11.7</td>\n",
       "      <td>12.6</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1917</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.4</td>\n",
       "      <td>14.3</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.4</td>\n",
       "      <td>18.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>18.1</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1918</td>\n",
       "      <td>19.7</td>\n",
       "      <td>17.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   \n",
       "1  1914   2.0   1.0   1.0   0.0   2.1   1.0   1.0   3.0   2.0   1.0   1.0  \\\n",
       "2  1915   1.0   1.0   0.0   2.0   2.0   2.0   1.0  -1.0  -1.0   1.0   1.0   \n",
       "3  1916   3.0   4.0   6.1   6.0   5.9   6.9   6.9   7.9   9.9  10.8  11.7   \n",
       "4  1917  12.5  15.4  14.3  18.9  19.6  20.4  18.5  19.3  19.8  19.5  17.4   \n",
       "5  1918  19.7  17.5  16.7  12.7  13.3  13.1  18.0  18.5  18.0  18.5  20.7   \n",
       "\n",
       "    Dec Average  \n",
       "1   1.0     1.0  \n",
       "2   2.0     1.0  \n",
       "3  12.6     7.9  \n",
       "4  18.1    17.4  \n",
       "5  20.4    18.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35ef3e6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 110 entries, 1 to 110\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Year     110 non-null    object\n",
      " 1   Jan      110 non-null    object\n",
      " 2   Feb      110 non-null    object\n",
      " 3   Mar      110 non-null    object\n",
      " 4   Apr      109 non-null    object\n",
      " 5   May      110 non-null    object\n",
      " 6   Jun      110 non-null    object\n",
      " 7   Jul      110 non-null    object\n",
      " 8   Aug      110 non-null    object\n",
      " 9   Sep      110 non-null    object\n",
      " 10  Oct      110 non-null    object\n",
      " 11  Nov      110 non-null    object\n",
      " 12  Dec      110 non-null    object\n",
      " 13  Average  110 non-null    object\n",
      "dtypes: object(14)\n",
      "memory usage: 12.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d44041",
   "metadata": {},
   "source": [
    "The data is now available in dataframe format. Begin Analyzing the data and draw some conclusions :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
